{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "import re\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "from statistics import mean\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-3-5-haiku-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"python|json|regex\",\n",
    "        \"solution_criteria\": \"Key criteria to evaluate the solution\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    response = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a3af468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'Create a regular expression to validate an AWS IAM username, which must be between 1-64 characters, can only contain alphanumeric characters, underscores, and hyphens',\n",
       "  'format': 'regex',\n",
       "  'solution_criteria': 'Regex should match valid IAM usernames and reject names with special characters or outside length range'},\n",
       " {'task': \"Write a Python function to convert an AWS EC2 instance type (e.g. 't2.micro') into a dictionary with size and family components\",\n",
       "  'format': 'python',\n",
       "  'solution_criteria': \"Function should correctly parse instance type string into dictionary with 'family' and 'size' keys\"},\n",
       " {'task': 'Create a JSON object representing the minimum configuration for an AWS S3 bucket policy that allows public read access',\n",
       "  'format': 'json',\n",
       "  'solution_criteria': 'JSON should define a bucket policy with a statement allowing GetObject action for all principals'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = generate_dataset()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "959e0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbec50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please solve the following task:\n",
    "\n",
    "    {test_case['task']}\n",
    "\n",
    "    * Respond only with Python, JSON, or Regex as specified.\n",
    "    * Do not include any explanations or additional text.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    output = chat(messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a9de5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "    \"\"\"Grades the output of a test case using another model or the model itself\"\"\"\n",
    "    eval_prompt = f\"\"\"\n",
    "    You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "    Original Task:\n",
    "    <task>\n",
    "    {test_case[\"task\"]}\n",
    "    </task>\n",
    "\n",
    "    Solution to Evaluate:\n",
    "    <solution>\n",
    "    {output}\n",
    "    </solution>\n",
    "\n",
    "    Criteria for Evaluation:\n",
    "    <criteria>\n",
    "    {test_case[\"solution_criteria\"]}\n",
    "    </criteria>\n",
    "\n",
    "    Output Format\n",
    "    Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "    - \"strengths\": An array of 1-3 key strengths\n",
    "    - \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "    - \"reasoning\": A concise explanation of your overall assessment\n",
    "    - \"score\": A number between 1-10\n",
    "\n",
    "    Respond with JSON. Keep your response concise and direct.\n",
    "    Example response shape:\n",
    "    {{\n",
    "        \"strengths\": string[],\n",
    "        \"weaknesses\": string[],\n",
    "        \"reasoning\": string,\n",
    "        \"score\": number\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_response = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee5464cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "    \n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c39301e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    # TODO - Grading\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "    score = (model_score + syntax_score) / 2  # Average the two scores\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1fc5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "\n",
    "    results = []\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean(result[\"score\"] for result in results)\n",
    "    print(f\"Average Score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af0fba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 8.5\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a68f731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output': '\\n^[a-zA-Z0-9_-]{1,64}$\\n',\n",
       "  'test_case': {'task': 'Create a regular expression to validate an AWS IAM username, which must be between 1-64 characters, can only contain alphanumeric characters, underscores, and hyphens',\n",
       "   'format': 'regex',\n",
       "   'solution_criteria': 'Regex should match valid IAM usernames and reject names with special characters or outside length range'},\n",
       "  'score': 9.0,\n",
       "  'reasoning': 'The regex captures the core requirements for IAM username validation with a straightforward pattern. It successfully restricts character types and enforces length limits. Minor improvements could enhance robustness.'},\n",
       " {'output': \"\\ndef parse_ec2_instance_type(instance_type):\\n    parts = instance_type.split('.')\\n    return {\\n        'family': parts[0],\\n        'size': parts[1] if len(parts) > 1 else None\\n    }\\n\",\n",
       "  'test_case': {'task': \"Write a Python function to convert an AWS EC2 instance type (e.g. 't2.micro') into a dictionary with size and family components\",\n",
       "   'format': 'python',\n",
       "   'solution_criteria': \"Function should correctly parse instance type string into dictionary with 'family' and 'size' keys\"},\n",
       "  'score': 8.0,\n",
       "  'reasoning': \"The solution provides a basic implementation for parsing EC2 instance types, but lacks robustness for real-world usage. It works for standard instance types like 't2.micro', but would fail with more complex naming conventions or invalid inputs.\"},\n",
       " {'output': '\\n{\\n    \"Version\": \"2012-10-17\",\\n    \"Statement\": [\\n        {\\n            \"Sid\": \"PublicReadGetObject\",\\n            \"Effect\": \"Allow\",\\n            \"Principal\": \"*\",\\n            \"Action\": [\\n                \"s3:GetObject\"\\n            ],\\n            \"Resource\": [\\n                \"arn:aws:s3:::bucket-name/*\"\\n            ]\\n        }\\n    ]\\n}\\n',\n",
       "  'test_case': {'task': 'Create a JSON object representing the minimum configuration for an AWS S3 bucket policy that allows public read access',\n",
       "   'format': 'json',\n",
       "   'solution_criteria': 'JSON should define a bucket policy with a statement allowing GetObject action for all principals'},\n",
       "  'score': 8.5,\n",
       "  'reasoning': 'The solution provides a basic, functional S3 bucket policy for public read access, but lacks specific security best practices. It meets the minimum requirement of allowing GetObject for all principals, but would benefit from more granular access controls.'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012930f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
